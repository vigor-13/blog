---
title: AI 플랫폼을 위한 스토리지 JuiceFS 도입기
description: ''
tags: ['react', 'ai', 'naver']
---

AiSuite는 네이버 개발자들이 사용하는 AI 플랫폼입니다. 네이버의 다양한 서비스가 AiSuite에서 개발 및 운영됩니다.

AiSuite는 Kubernetes 기반의 컨테이너 환경을 제공해 고비용의 GPU 자원을 효율적으로 관리합니다. 또한 Kubeflow를 지원하여 AI 개발뿐만 아니라 학습, 서빙을 연계하는 AI 파이프라인 구축이 가능합니다. C3, Cuve, CQuery와 같은 사내 데이터 플랫폼을 활용하는 Kubeflow 파이프라인 컴포넌트도 사용할 수 있습니다.

## 스토리지 검토 {#스토리지-검토}

AI 플랫폼을 운영하면서 가장 어려운 것은 AI 워크로드에 적합한 스토리지를 제공하는 것입니다. LLM이 확산되면서 좋은 AI 모델을 생성하기 위해 필요한 데이터의 크기는 점점 더 커지고 있으며, 분산 학습을 위해서는 다수의 노드에서 동시에 접근할 수 있어야 합니다. 또한 Llama 2, MPT 등 빠르게 등장하는 다양한 LLM 오픈소스를 쉽게 적용해볼 수 있어야 합니다.

정리해보면 AI 플랫폼에 적합한 스토리지의 요구 사항은 다음과 같습니다.

JuiceFS는 파일을 다루기 위해 다음과 같은 개념을 도입했다. 물리적으로 떨어져 느리고 수정하기 어려운 Object Storage의 단점을 보완한다.

### skldfjl {#skldfjl}

#### sdklfjlsd {#sdklfjlsd}

#### sdklfjlsd2 {#sdklfjlsd2}

- Chunk: 각 파일은 64MB 단위의 Chunk로 분리해 관리한다. 대규모 파일의 경우에도 오프셋을 기반으로 동시에 읽거나 쓸 수 있다. 대규모 데이터를 다루기에 효과적이다.
- Slice: 각 Chunk는 하나 또는 여러 Slice로 이루어진다. Slice는 각 쓰기마다 생성되어 동일한 Chunk에 겹쳐질 수 있다. Chunk를 읽을 때는 최신 Slice를 우선해 읽는다. 다만, Slice가 많아지면 읽기 성능이 저하되므로 주기적으로 Slice를 하나로 병합한다. 이로써 JuiceFS는 유연하게 파일을 변경할 수 있어, Object Storage가 데이터 수정이 어렵다는 단점을 보완한다.
- Block: 실제 저장소에는 Slice가 기본값 4MB(16MB까지 설정 가능) 단위의 Block으로 분리되어 저장된다. Chunk, Slice는 논리적인 개념이며 실제 저장소에서 확인할 수 있는 데이터는 Block이다. 작은 Block으로 나누고 동시에 처리함으로써 멀리 떨어져 느린 Object Storage의 단점을 보완한다.

## 캐싱 {#캐싱}

성능 향상을 위해 JuiceFS에는 여러 단계의 캐싱 레이어가 있다.

읽기 요청 시 커널 페이지 캐시, 클라이언트 프로세스 캐시, 로컬 디스크 캐시로부터 읽기를 시도한 후, 없으면 저장소로부터 데이터를 읽어온다. 저장소로 읽어온 데이터는 비동기적으로 각 캐싱 레이어에 캐싱되고 이후 동일한 데이터는 빠르게 가져온다.

## Alluxio와 JuiceFS 비교 {#Alluxio와-JuiceFS-비교}

Alluxio는 master, worker 서버를 구동하고 운영해야 한다는 부담이 있다. 또한 전체 사용자가 이를 공유하므로 Alluxio에 문제가 발생하면 전체 사용자에게 영향을 준다는 문제도 있다.

### sdkfjdlsfjkl {#sdkfjdlsfjkl}

JuiceFS는 기존의 익숙한 저장소, DB를 그대로 메타데이터 엔진, 데이터 스토리지로 구성할 수 있으며, JuiceFS 클라이언트만 있으면 별도의 서버 구동 없이 사용할 수 있다. 또한 각 사용자가 개별적으로 메타데이터 엔진, 데이터 스토리지를 마련해서 사용할 수 있으므로 서로 영향을 주지 않는다.
